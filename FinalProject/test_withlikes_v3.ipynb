{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://megapx.dcard.tw/v1/images/926dcd27-8107-4745-a07f-3c07a4baa93d/encode/640.webp\n",
      "https://megapx.dcard.tw/v1/images/e6c4f919-ead0-4f19-9ace-470914a5deba/encode/640.webp\n",
      "https://megapx.dcard.tw/v1/images/555a8922-a9b7-4deb-8f06-9bfd0e6ad6c1/encode/640.webp\n",
      "https://megapx.dcard.tw/v1/images/200be639-7079-47a2-b828-ac0343ae2b20/encode/640.webp\n",
      "https://megapx.dcard.tw/v1/images/dcda7584-b1c0-4ba1-87a7-c80366cc3002/encode/640.webp\n",
      "https://megapx.dcard.tw/v1/images/ba60aec9-c4cf-4ea0-88f4-7c7d54614ffe/encode/640.webp\n",
      "https://megapx.dcard.tw/v1/images/bc788439-f49c-4651-949d-da9c0db44ebe/encode/640.webp\n",
      "https://megapx.dcard.tw/v1/images/d1eb0cd7-af87-47b3-8af9-28ca5dcc8230/encode/640.webp\n",
      "https://megapx.dcard.tw/v1/images/3dc22fca-5582-4caa-b152-cc5f4803c61c/encode/640.webp\n",
      "https://megapx.dcard.tw/v1/images/c2f52057-427f-47d9-ae37-ccc3e8cb16cc/encode/640.webp\n",
      "https://megapx.dcard.tw/v1/images/86bdb6b9-82d0-4750-bd8e-fcaeaf9a59ec/encode/640.webp\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-25ce25874e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mlist_req\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 請求\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;31m#將整個網站的程式碼爬下來\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mgetdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_req\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[0malldata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 將另一個陣列插在最後面\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mlast_article\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 取出最後一篇文章\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# 先清空資料夾、多了評論數與標籤、變更圖片取名規則\n",
    "# 圖片只會下載10張梗圖\n",
    "\n",
    "# Load all URL images\n",
    "import requests,os,glob\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "s=0\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "headers = {'user-agent': user_agent}\n",
    "\n",
    "url = 'https://www.dcard.tw/f/meme'\n",
    "html = requests.get(url,headers=headers)\n",
    "html.encoding=\"UTF-8\"\n",
    "\n",
    "sp = BeautifulSoup(html.text,'html.parser')\n",
    "#建立images存圖片\n",
    "images_dir=\"images/\"\n",
    "if not os.path.exists(images_dir):\n",
    "    os.mkdir(images_dir)\n",
    "\n",
    "pc_files = glob.glob(images_dir+'*.jpg')#刪除資料夾內的圖片\n",
    "for pc_file in pc_files:\n",
    "    try:\n",
    "        os.remove(pc_file)\n",
    "    except OSError as e:\n",
    "        print(f\"Error:{ e.strerror}\")\n",
    "\n",
    "all_links=sp.find_all('img')\n",
    "for link in all_links:\n",
    "#取 src 和 href 屬性内容\n",
    "    if s==11:\n",
    "        break\n",
    "    src=link.get('src')\n",
    "    href = link.get('href') #指定一個URL看連結要到哪\n",
    "    attrs=[src,href]\n",
    "    for attr in attrs:\n",
    "#讀取 .jpg 和 .png檔\n",
    "        if attr != None and ('.webp' in attr):\n",
    "            full_path = attr\n",
    "            filename= full_path.split('/')[-1]#取得圖檔名\n",
    "            print(full_path)#儲存圖片\n",
    "            if s!=0:\n",
    "                try :\n",
    "                    headers = {'user-agent':ua.random}\n",
    "                    image = requests.get(full_path,headers=headers)\n",
    "                    f = open(images_dir + str(s)+\".jpg\", \"wb\")\n",
    "                    f.write(image.content)\n",
    "                    f.close()\n",
    "                    #print(\"我是\",s)\n",
    "                except:\n",
    "                    print(\"{}無法讀取!\".format(filename))\n",
    "            s+=1\n",
    "#以下使用api獲取按讚數\n",
    "#參考https://marketingliveincode.com/?p=5009\n",
    "alldata = []\n",
    "last_article = ''\n",
    "likeCount=[]\n",
    "commentCount=[]\n",
    "topics={}\n",
    "url = 'https://www.dcard.tw/service/api/v2/forums/meme/posts?popular=true&limit=10'\n",
    "for i in range(5):\n",
    "    if i != 0: # 判斷是否是第一次執行\n",
    "        request_url = url +'&before='+ str(last_article)\n",
    "    else:\n",
    "        request_url = url # 第一次執行，不須加上後方的before\n",
    "    ua = UserAgent()\n",
    "    headers = {'user-agent': ua.random}\n",
    "    list_req = requests.get(request_url,headers=headers) # 請求\n",
    "    #將整個網站的程式碼爬下來\n",
    "    getdata = json.loads(list_req.content)\n",
    "    alldata.extend(getdata) # 將另一個陣列插在最後面\n",
    "    last_article = getdata[-1]['id'] # 取出最後一篇文章\n",
    "    \n",
    "for i in range(10):\n",
    "    topicscount=len(alldata[i]['topics'])\n",
    "    for j in range(topicscount):\n",
    "        if alldata[i]['topics'][j] not in topics:\n",
    "            topics[alldata[i]['topics'][j]]=[str(i)+\".jpg\"]\n",
    "        else:\n",
    "            topics[alldata[i]['topics'][j]].insert(-1,str(i)+\".jpg\")\n",
    "with open(\"test.txt\",\"w+\",encoding=\"UTF-8-sig\")as f:\n",
    "    for i in range(10):\n",
    "        likeCount.append(alldata[i]['likeCount'])\n",
    "    for i in range(10):\n",
    "        commentCount.append(alldata[i]['commentCount'])\n",
    "    print(\"likeCount:\",likeCount)\n",
    "    print(\"commentCount:\",commentCount)\n",
    "    print(\"topics:\",topics)\n",
    "    f.write(str(likeCount)+\"\\n\")\n",
    "    f.write(str(commentCount)+\"\\n\")\n",
    "    f.write(str(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
